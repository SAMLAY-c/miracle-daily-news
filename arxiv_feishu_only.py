#!/usr/bin/env python3
"""
åªå¤„ç† arXiv è®ºæ–‡å¹¶å†™å…¥é£ä¹¦å¤šç»´è¡¨æ ¼çš„ç¨‹åº
"""

import requests
import json
import time
import os
from dotenv import load_dotenv
from arxiv_fetcher import ArxivFetcher

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ================= é…ç½®åŒºåŸŸ =================

# 1. SiliconFlow (DeepSeek) é…ç½®
SILICON_KEY = os.getenv("SILICON_KEY", 'sk-keakcptlwtptnosbliohqompvsgxdtwctolxqjiwxddahyqk')
MODEL_NAME = "deepseek-ai/DeepSeek-V3"

# 2. é£ä¹¦æœºå™¨äººé…ç½®
FEISHU_APP_ID = os.getenv("FEISHU_APP_ID", 'cli_a9db5c1e15795bc0')
FEISHU_APP_SECRET = os.getenv("FEISHU_APP_SECRET", 'OBeaUaz1mtuQPPLuhgO5kfKCaPluKBVI')

# 3. é£ä¹¦å¤šç»´è¡¨æ ¼é…ç½®
FEISHU_BITABLE_APP_TOKEN = os.getenv("FEISHU_BITABLE_APP_TOKEN", 'ECRabFuuRaGRBvsgo4scULlSn1d')
FEISHU_TABLE_ID = os.getenv("FEISHU_BITABLE_TABLE_ID", 'tblMKVkH5tc2pnTK')

# arXiv é…ç½®
ARXIV_LIMIT = int(os.getenv("ARXIV_LIMIT", 10))  # æ¯æ¬¡è·å–10ç¯‡è®ºæ–‡
ARXIV_CATEGORIES = os.getenv("ARXIV_CATEGORIES", "cs.CL,cs.AI,cs.LG,cs.CV").split(",")  # LLMç›¸å…³ç±»åˆ«ï¼šCL(è®¡ç®—è¯­è¨€å­¦), AI, LG(æœºå™¨å­¦ä¹ ), CV(è®¡ç®—æœºè§†è§‰-å¤šæ¨¡æ€)

# ===========================================

# arXiv è®ºæ–‡ä¸“ç”¨æç¤ºè¯æ¨¡æ¿ï¼ˆä¸“æ³¨LLMåˆ†æï¼‰
ARXIV_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„AIç ”ç©¶å‘˜å’ŒLLMæŠ€æœ¯ä¸“å®¶ï¼Œä¸“æ³¨äºå¤§è¯­è¨€æ¨¡å‹é¢†åŸŸã€‚è¯·åˆ†æä»¥ä¸‹ arXiv è®ºæ–‡ä¿¡æ¯ï¼Œé‡ç‚¹è¯„ä¼°å…¶åœ¨LLMé¢†åŸŸçš„æŠ€æœ¯ä»·å€¼å’Œå•†ä¸šæ½œåŠ›ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¿”å›ç»“æœï¼ˆä¸è¦è¿”å› Markdown ä»£ç å—ï¼‰ã€‚

éœ€è¦åˆ†æçš„ç»´åº¦ï¼ˆJSON Key å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š
1. "summary": æŠ€æœ¯è´¡çŒ®æ‘˜è¦ï¼ˆä¸­æ–‡ï¼Œ60å­—å†…ï¼‰ã€‚
2. "category": æ‰€å±é¢†åŸŸï¼Œå¿…é¡»ä»ä»¥ä¸‹é€‰é¡¹ä¸­ä¸¥æ ¼é€‰æ‹©ä¸€ä¸ªï¼š
   ["å¤§è¯­è¨€æ¨¡å‹", "æ¨¡å‹æ¶æ„", "è®­ç»ƒä¼˜åŒ–", "æ¨ç†åŠ é€Ÿ", "å¤šæ¨¡æ€", "Agentç³»ç»Ÿ", "RAGæ£€ç´¢å¢å¼º", "æ¨¡å‹è¯„ä¼°", "æ•°æ®é›†", "å…¶ä»–"]
3. "innovation": æŠ€æœ¯åˆ›æ–°æ€§è¯„ä¼°ï¼Œç®€è¿°å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹å’Œå¯¹LLMé¢†åŸŸçš„è´¡çŒ®ï¼ˆä¸­æ–‡ï¼Œ80å­—å†…ï¼‰ã€‚
4. "practicality": å®ç”¨æ€§è¯„ä¼°ï¼ŒæŠ€æœ¯è½åœ°çš„å¯è¡Œæ€§å’Œéš¾åº¦ï¼ˆä¸­æ–‡ï¼Œ80å­—å†…ï¼‰ã€‚
5. "commercial_score": å•†ä¸šè½åœ°æ½œåŠ›è¯„åˆ†ï¼Œè¿”å›æ•´æ•° 1 åˆ° 5ï¼ˆ5ä¸ºæœ€é«˜ï¼‰ã€‚
6. "recommendation": æ¨èæŒ‡æ•°ï¼Œå¿…é¡»ä»ä»¥ä¸‹é€‰é¡¹ä¸­ä¸¥æ ¼é€‰æ‹©ä¸€ä¸ªï¼š
   ["ğŸ”¥ å¿…è¯»è®ºæ–‡", "ğŸ‘€ é‡è¦è¿›å±•", "â˜•ï¸ å­¦æœ¯å‚è€ƒ", "ğŸ“„ æ–¹æ³•è®ºè´¡çŒ®"]

è®ºæ–‡æ ‡é¢˜ï¼š{title}
è®ºæ–‡æ‘˜è¦ï¼š{summary}
ä½œè€…ï¼š{authors}
ç±»åˆ«ï¼š{categories}
"""

def get_tenant_token():
    """è·å–é£ä¹¦æœºå™¨äººè®¿é—®å‡­è¯"""
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    payload = {"app_id": FEISHU_APP_ID, "app_secret": FEISHU_APP_SECRET}
    try:
        resp = requests.post(url, json=payload)
        if resp.status_code != 200:
            print(f"âŒ æœºå™¨äºº Token è·å–å¤±è´¥: {resp.text}")
            return None
        return resp.json().get("tenant_access_token")
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
        return None

def get_arxiv_papers(limit=ARXIV_LIMIT, categories=ARXIV_CATEGORIES):
    """è·å–æœ€æ–° arXiv è®ºæ–‡ï¼ˆå¸¦å»é‡åŠŸèƒ½ï¼‰"""
    print(f"ğŸ“š æ­£åœ¨è·å– arXiv æœ€æ–°è®ºæ–‡...")
    print(f"   ç±»åˆ«: {', '.join(categories)}")
    print(f"   æ•°é‡: {limit}")

    try:
        fetcher = ArxivFetcher(delay_seconds=2)  # 2ç§’é—´éš”ï¼Œéµå®ˆé€Ÿç‡é™åˆ¶
        papers = fetcher.fetch_latest_papers(
            categories=categories,
            max_results=limit
        )

        # ä¸ºæ¯ä¸ªè®ºæ–‡æ·»åŠ æ¥æºæ ‡è¯†
        for paper in papers:
            paper['source'] = 'arxiv'

        print(f"âœ… æˆåŠŸè·å– {len(papers)} ç¯‡æ–°è®ºæ–‡")
        return papers

    except Exception as e:
        print(f"âŒ è·å– arXiv è®ºæ–‡å¤±è´¥: {e}")
        return []

def analyze_and_write(arxiv_papers, token):
    """AI åˆ†æ arXiv è®ºæ–‡å¹¶å†™å…¥é£ä¹¦"""
    # é£ä¹¦å†™å…¥æ¥å£ï¼ˆä½¿ç”¨å•æ¡è®°å½•æ¥å£ï¼‰
    feishu_url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{FEISHU_BITABLE_APP_TOKEN}/tables/{FEISHU_TABLE_ID}/records"
    feishu_headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}

    # DeepSeek æ¥å£
    ai_url = "https://api.siliconflow.cn/v1/chat/completions"
    ai_headers = {"Authorization": f"Bearer {SILICON_KEY}", "Content-Type": "application/json"}

    success_count = 0
    failed_count = 0

    for paper in arxiv_papers:
        title = paper.get('title', 'æ— æ ‡é¢˜')
        print(f"\nğŸ§  æ­£åœ¨åˆ†æ: {title[:50]}...")

        try:
            # 1. è°ƒç”¨ AI åˆ†æ
            payload = {
                "model": MODEL_NAME,
                "messages": [{"role": "user", "content": ARXIV_PROMPT_TEMPLATE.format(
                    title=title,
                    summary=paper.get('summary', '')[:200],
                    authors=', '.join(paper.get('authors', [])[:3]),
                    categories=', '.join(paper.get('categories', [])[:3])
                )}],
                "response_format": {"type": "json_object"},
                "temperature": 0.3
            }

            ai_resp = requests.post(ai_url, headers=ai_headers, json=payload)
            ai_data = ai_resp.json()

            # è§£æ AI è¿”å›çš„å†…å®¹
            content_str = ai_data['choices'][0]['message']['content']
            analysis = json.loads(content_str)

            # 2. æ„é€ é£ä¹¦æ•°æ® Payloadï¼ˆä½¿ç”¨å­—æ®µåç§°ï¼‰
            current_time_ms = int(time.time() * 1000)

            fields = {
                "è®ºæ–‡æ ‡é¢˜": title,
                "ä¸€å¥è¯æ‘˜è¦": analysis.get('summary', 'åˆ†æå¤±è´¥'),
                "æ‰€å±é¢†åŸŸ": analysis.get('category', 'å…¶ä»–'),
                "æŠ€æœ¯åˆ›æ–°æ€§": analysis.get('innovation', ''),
                "å®ç”¨æ€§è¯„ä¼°": analysis.get('practicality', ''),
                "å•†ä¸šæ½œåŠ›": analysis.get('commercial_score', 3),
                "AIæ¨è": analysis.get('recommendation', 'â˜•ï¸ å­¦æœ¯ä»·å€¼'),
                "å‘å¸ƒæ—¥æœŸ": current_time_ms,
                "æ”¶è—æ—¥æœŸ": current_time_ms,
                "åŸæ–‡é“¾æ¥": {
                    "text": "Arxiv Link",
                    "link": paper.get('id', '')
                }
            }

            # 3. é€æ¡å†™å…¥é£ä¹¦
            write_resp = requests.post(feishu_url, headers=feishu_headers, json={"fields": fields})
            write_res = write_resp.json()

            if write_res.get('code') == 0:
                print(f"   ğŸ’¾ [å†™å…¥æˆåŠŸ] å•†ä¸šæ½œåŠ›: {analysis.get('commercial_score')}æ˜Ÿ | {analysis.get('recommendation')}")
                success_count += 1
            else:
                print(f"   âŒ [å†™å…¥å¤±è´¥] {write_res.get('msg')}")
                if 'error' in write_res:
                    print(f"      è¯¦æƒ…: {write_res['error'].get('message')}")
                failed_count += 1

        except Exception as e:
            print(f"   âŒ å¤„ç†å‡ºé”™: {e}")
            failed_count += 1

        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(1)

    print(f"\nğŸ‰ arXiv å¤„ç†ä»»åŠ¡ç»“æŸï¼")
    print(f"   âœ… æˆåŠŸåˆ†æå¹¶å†™å…¥: {success_count} ç¯‡è®ºæ–‡")
    print(f"   âŒ å¤±è´¥: {failed_count} ç¯‡è®ºæ–‡")
    print(f"   ğŸ“Š å¤„ç†æ•ˆç‡: {success_count}/{len(arxiv_papers)}")
    print(f"   ğŸ“Š é£ä¹¦è¡¨æ ¼é“¾æ¥: https://pcnlp18cy9bm.feishu.cn/base/{FEISHU_BITABLE_APP_TOKEN}?table={FEISHU_TABLE_ID}")

if __name__ == "__main__":
    print("ğŸš€ arXiv è®ºæ–‡é£ä¹¦è‡ªåŠ¨åŒ–æƒ…æŠ¥ç«™")
    print("=" * 50)

    # 1. è·å– Token
    t_token = get_tenant_token()

    if t_token:
        # 2. è·å– arXiv è®ºæ–‡ï¼ˆå¸¦å»é‡ï¼‰
        arxiv_list = get_arxiv_papers(limit=ARXIV_LIMIT, categories=ARXIV_CATEGORIES)

        if arxiv_list:
            # 3. åˆ†æ + å†™å…¥
            analyze_and_write(arxiv_list, t_token)
        else:
            print("âš ï¸ æœªè·å–åˆ°è®ºæ–‡æ•°æ®")
    else:
        print("âš ï¸ æ— æ³•è¿æ¥é£ä¹¦ï¼Œè¯·æ£€æŸ¥ App ID å’Œ Secret")